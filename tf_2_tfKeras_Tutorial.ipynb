{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_2_tfKeras_Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPL1dkeoCvT3n6PK0mOtN7h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daveking63/Jupyter-iPython-Notebooks-Deep-Learning-Notes/blob/master/tf_2_tfKeras_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO-27shVcYzz",
        "colab_type": "text"
      },
      "source": [
        "## Notes from Jason Brownlee's\n",
        "## TensorFlow 2 Tutorial: Get Started in Deep Learning with tf.keras\n",
        "\n",
        "### What are Keras and tf.keras\n",
        "\n",
        "Keras is an open-source deep learning library in Python.  Started in 2015 by Francois Chollet. In 2019 Google released a new version of TensorFlow that directly integrated the Keras API. This integration is usually referred to as the tf.keras interface.\n",
        "\n",
        "In using TensorFlow and Keras to build, train and test a deep learning model, the first step is to import them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnIZUIJUcVdz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6f95cf55-3881-4466-b36a-7c3cbe1c05e1"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n",
            "2.3.0-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da2G9cpMedqR",
        "colab_type": "text"
      },
      "source": [
        "### 5-Step Model Life Cycle\n",
        "\n",
        "\n",
        "Once imported, you can start the 5-Step Model Life-Cycle that includes the following:\n",
        "\n",
        "<ol>\n",
        "<li>Define the Model - select the type and choose the architecture or network typology (using either the Sequential or Functional API.</li>\n",
        "<li>Compile the Model -- select a loss function, optimization procedure, and sometimes performance metric(s), then compile the model using the chosen configuration.</li>\n",
        "<li>Fit the Model - select the training configuration (epochs and batch size), then call a  function to perform the process.</li>\n",
        "<li>Evaluate the Model - using a testing dataset, call a function to determine the loss or other metrics.</li>\n",
        "<li>Use the Model to Make Predictions -- using new data, call a function to predict a class label, probability, or numerical value (depending on the problem of interest).</li>\n",
        "</ol>\n",
        "\n",
        "To illustrate we'll first consider a simple Sequential Model.\n",
        "\n",
        "**Sequential Model API (Simple)**\n",
        "\n",
        "Called 'sequential' because involves defining a Sequential Class and adding layers to the model one by one in a linear manner from input to output.\n",
        "\n",
        "Here, were creating a Sequential MLP model with 8 inputs, one hidden layer with 10 notes, then an output layer with one node to predict a numerical value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCPeWUWOfE4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# define the model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10,input_shape=(8,)))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkLSleNhiLD4",
        "colab_type": "text"
      },
      "source": [
        "### Functional Model API (Advanced)\n",
        "\n",
        "More complex and flexible, involving the connection of the output layer to the input of another layer. First, we define the input class. Next, we connect one or more fully connected layers to the input, then finally the output layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD2zHOSHi8HL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "x_in = Input(shape=(8,))\n",
        "x = Dense(10)(x_in)\n",
        "x_out = Dense(1)(x)\n",
        "model = Model(inputs=x_in, outputs=x_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev1ignZHkLV5",
        "colab_type": "text"
      },
      "source": [
        "### How to Develop Deep Learning Models\n",
        "\n",
        "**Develop Multilayer Perceptron Models (MLP)**\n",
        "\n",
        "Standard neural network model with layers of nodes where each node is connected to all the outputs from previous layer and the output of each node is connected to all inputs for nodes in the next layer.\n",
        "\n",
        "MLPs are created using one or more Dense Layers.  It is appropriate for tabular data where each column is a variable and each row is an entity or sample. With MLP there are 3 predictive modeling programs of interest: binary classification, multiclass classification and regression.\n",
        "\n",
        "**MLP for Binary Classification**\n",
        "\n",
        "Focus on the *Ionosphere* binary (two-class) classification dataset which predicts whether a structure is in the atmosphere or not given radar returns.\n",
        "\n",
        "We'll use a LabelEncoder to encode string labels to integer values of 0 or 1. Then fit the model 67% of the data for training, and 33% for evaluation. We'll employ the 'relu' activation function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SYwWREnmojK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import key libraries\n",
        "\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CyfDYSmnnuy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "57e01753-cb1a-4a9a-d24b-2010042a3ab2"
      },
      "source": [
        "# load dataset\n",
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
        "df = read_csv(path, header=None)\n",
        "\n",
        "# split into input and output columns\n",
        "X, y = df.values[:, :-1], df.values[:, -1]\n",
        "\n",
        "# ensure all data are floating point values\n",
        "X = X.astype('float32')\n",
        "\n",
        "# encode strings to integer\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(351, 34)\n",
            "(351,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imaa9nmpoQsk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6321a71-b85c-4d08-9961-3d447ba402e4"
      },
      "source": [
        "# split into train and test datasets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "# determine the number of input features\n",
        "n_features = X_train.shape[1]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(235, 34) (116, 34) (235,) (116,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIVWZaELoQ0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH7k9VzxoQ9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fJ6g0Kjo9DH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c669fee8-c26d-4a68-8575-860258ca9ce0"
      },
      "source": [
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcc7b8f29e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gAxzmFEoRE-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbb45a07-5c25-4df3-cff8-8ac104884375"
      },
      "source": [
        "# evaluate the model\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Accuracy: %.3f' % acc)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmQosaFIoRLw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d30d5258-9088-45c6-a5a2-26eb8424c22e"
      },
      "source": [
        "# make a prediction\n",
        "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
        "yhat = model.predict([row])\n",
        "print('Predicted: %.3f' % yhat)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: 0.994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3abItpR8wuiY",
        "colab_type": "text"
      },
      "source": [
        "**MLP for Multiclass Classification**\n",
        "\n",
        "Predicting the species of iris flower given measurements of the flower. Uses the well-known iris dataset. Here, model will have one node for each class in the output layer and use the softmax activation function. The loss function is 'sparse_categorical_crossentropy' which is used for integer encoded class labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0QZ_c2dxasr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "\n",
        "from numpy import argmax\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgJdEm6XxnfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the dataset\n",
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv'\n",
        "df = read_csv(path, header=None)\n",
        "\n",
        "# split into input and output columns\n",
        "X, y = df.values[:, :-1], df.values[:, -1]\n",
        "\n",
        "# ensure all data are floating point values\n",
        "X = X.astype('float32')\n",
        "\n",
        "# encode strings to integer\n",
        "y = LabelEncoder().fit_transform(y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9KKrj3Cxo8F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03aceec7-d4db-4a0d-80f4-8385dcdf514b"
      },
      "source": [
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# determine the number of input features\n",
        "n_features = X_train.shape[1]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 4) (50, 4) (100,) (50,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbfrwshaxpLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb1N7yZrxpZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mTq3NsTxpkk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b43d93f-072d-43a9-f9ed-603f9c608221"
      },
      "source": [
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcc78914978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fr9WKX2yE8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c64a049-2ffe-47d3-90f4-0ee7590004cb"
      },
      "source": [
        "# evaluate the model\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Accuracy: %.3f' % acc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVGf3sAkyHI5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17a248d4-5d1f-4b85-e016-0c744d451d70"
      },
      "source": [
        "# make a prediction\n",
        "row = [5.1,3.5,1.4,0.2]\n",
        "yhat = model.predict([row])\n",
        "print('Predicted: %s (class=%d)' % (yhat, argmax(yhat)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: [[9.785259e-01 2.052212e-02 9.520305e-04]] (class=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbIIxvNxydkA",
        "colab_type": "text"
      },
      "source": [
        "MLP for Regression\n",
        "\n",
        "Like earlier source, uses Boston Housing dataset to predict a single numerical value - house value based on properties of the house and neighborhood. Ergo, the output has a single node and uses the default or linear activation function. The MSE loss is minimized when fitting the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeJ8VDzRzEJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mlp for regression\n",
        "\n",
        "from numpy import sqrt\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM_L_f6mzOuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee6366f6-c552-4771-971c-8b858d368975"
      },
      "source": [
        "# load the dataset\n",
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
        "df = read_csv(path, header=None)\n",
        "\n",
        "# split into input and output columns\n",
        "X, y = df.values[:, :-1], df.values[:, -1]\n",
        "\n",
        "# split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "# determine the number of input features\n",
        "n_features = X_train.shape[1]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(339, 13) (167, 13) (339,) (167,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "darOhtp8zb_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmQIVEpIzcMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJpC0aKHzcWp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c4a7fa3-f8f8-47a8-e6f2-f53c7e00ce1e"
      },
      "source": [
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcc77046dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhHaPIR2zcVa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3d1f43e-e71f-4cec-d7be-50988446d687"
      },
      "source": [
        "# evaluate the model\n",
        "error = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('MSE: %.3f, RMSE: %.3f' % (error, sqrt(error)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 30.539, RMSE: 5.526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pdi51oozcR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f16464c-ada0-4e6a-b22e-57ffa02e47d8"
      },
      "source": [
        "# make a prediction\n",
        "row = [0.00632,18.00,2.310,0,0.5380,6.5750,65.20,4.0900,1,296.0,15.30,396.90,4.98]\n",
        "yhat = model.predict([row])\n",
        "print('Predicted: %.3f' % yhat)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: 29.580\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNGLVRW40GRf",
        "colab_type": "text"
      },
      "source": [
        "**Develop Convolutional Neural Network Models**\n",
        "\n",
        "Convolutional Neural Networks, or CNNs for short, are a type of network designed for image input.\n",
        "\n",
        "They are comprised of models with convolutional layers that extract features (called feature maps) and pooling layers that distill features down to the most salient elements.\n",
        "\n",
        "This example uses the well-known, and often used, MNIST digitized handwritten images dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGbWvB-20bUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "from numpy import unique\n",
        "from numpy import argmax\n",
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_7CpKde0blq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "16d9011a-6dc1-4085-babe-9ee9c7395215"
      },
      "source": [
        "# load dataset\n",
        "(x_train, y_train), (x_test, y_test) = load_data()\n",
        "\n",
        "# reshape data to have a single channel\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], x_test.shape[2], 1))\n",
        "\n",
        "# determine the shape of the input images\n",
        "in_shape = x_train.shape[1:]\n",
        "\n",
        "# determine the number of classes\n",
        "n_classes = len(unique(y_train))\n",
        "print(in_shape, n_classes)\n",
        "\n",
        "# normalize pixel values\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(28, 28, 1) 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5TtHGBi0bwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), activation='relu', kernel_initializer='he_uniform', input_shape=in_shape))\n",
        "model.add(MaxPool2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "# define loss and optimizer\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irt3KpkA0br2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define loss and optimizer\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC5JJBpw0b0l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c96b47cc-50bc-4813-8540-5f1f8ba8989d"
      },
      "source": [
        "# fit the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128, verbose=0)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcc74e98b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ammzV3D0cPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ed8abf0-ddc2-48b6-bf53-24a463545a90"
      },
      "source": [
        "# evaluate the model\n",
        "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Accuracy: %.3f' % acc)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsTL1RRg1OrX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65c918bf-5b03-482c-8f94-0b1660dc6ea4"
      },
      "source": [
        "# make a prediction\n",
        "image = x_train[0]\n",
        "image.shape\n",
        "#yhat = model.predict([[image]]) -- error in program\n",
        "#print('Predicted: class=%d' % argmax(yhat))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfxyrrg44WY_",
        "colab_type": "text"
      },
      "source": [
        "**Develop Recurrent Neural Network Models**\n",
        "\n",
        "Designed to operate on sequences of data. Proven effective in NLP and modest success with time series.  Most popular type of RNN is Long Short-Term Memory Network (LSTM).  Utilize car sales dataset to demonstrated RNN for univariate time series. Will work with moving 5 month data to predict current month's data. To do this will utilize a function split_sequence() that will split input sequence into windows. Used the last 12 months of data.\n",
        "\n",
        "LSTM expects dataset with 2 dimensions - first is the number of time steps (here 5) and second is the number of observations per time step (here 1).\n",
        "\n",
        "Because it's a regression type problem, we'll use linear activation function in the output layer and optimize MSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDMjObQT5nFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "from numpy import sqrt\n",
        "from numpy import asarray\n",
        "from pandas import read_csv\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn asarray(X), asarray(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwVuFRay52UB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8dfec62a-7c35-4a34-d958-38b0161cefa2"
      },
      "source": [
        "# load the dataset\n",
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-car-sales.csv'\n",
        "df = read_csv(path, header=0, index_col=0, squeeze=True)\n",
        "# retrieve the values\n",
        "values = df.values.astype('float32')\n",
        "# specify the window size\n",
        "n_steps = 5\n",
        "# split into samples\n",
        "X, y = split_sequence(values, n_steps)\n",
        "# reshape into [samples, timesteps, features]\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "# split into train/test\n",
        "n_test = 12\n",
        "X_train, X_test, y_train, y_test = X[:-n_test], X[-n_test:], y[:-n_test], y[-n_test:]\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(91, 5, 1) (12, 5, 1) (91,) (12,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG0M1th_55Yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, activation='relu', kernel_initializer='he_normal', input_shape=(n_steps,1)))\n",
        "model.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdm5KpgM57yG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofCHwkpJ5-SB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c7d4862-c96b-4369-f32f-9675c489e7dd"
      },
      "source": [
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=350, batch_size=32, verbose=2, validation_data=(X_test, y_test))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/350\n",
            "3/3 - 0s - loss: 1367388800.0000 - mae: 35310.4453 - val_loss: 734258496.0000 - val_mae: 26830.6035\n",
            "Epoch 2/350\n",
            "3/3 - 0s - loss: 367529088.0000 - mae: 17555.8262 - val_loss: 125649880.0000 - val_mae: 10647.7100\n",
            "Epoch 3/350\n",
            "3/3 - 0s - loss: 56904500.0000 - mae: 6465.5371 - val_loss: 17345574.0000 - val_mae: 3717.3691\n",
            "Epoch 4/350\n",
            "3/3 - 0s - loss: 17510352.0000 - mae: 3308.5459 - val_loss: 91431480.0000 - val_mae: 8145.0015\n",
            "Epoch 5/350\n",
            "3/3 - 0s - loss: 64788436.0000 - mae: 6711.6270 - val_loss: 146930736.0000 - val_mae: 10917.4365\n",
            "Epoch 6/350\n",
            "3/3 - 0s - loss: 91749504.0000 - mae: 8418.9297 - val_loss: 143156848.0000 - val_mae: 10625.0244\n",
            "Epoch 7/350\n",
            "3/3 - 0s - loss: 66038976.0000 - mae: 6838.6196 - val_loss: 93388640.0000 - val_mae: 7641.4595\n",
            "Epoch 8/350\n",
            "3/3 - 0s - loss: 34552464.0000 - mae: 4442.5054 - val_loss: 61954756.0000 - val_mae: 7309.8599\n",
            "Epoch 9/350\n",
            "3/3 - 0s - loss: 32986418.0000 - mae: 4622.6777 - val_loss: 73378112.0000 - val_mae: 8282.8379\n",
            "Epoch 10/350\n",
            "3/3 - 0s - loss: 33849836.0000 - mae: 5061.2168 - val_loss: 60388460.0000 - val_mae: 7479.8320\n",
            "Epoch 11/350\n",
            "3/3 - 0s - loss: 26039576.0000 - mae: 4281.1455 - val_loss: 41430356.0000 - val_mae: 5942.5039\n",
            "Epoch 12/350\n",
            "3/3 - 0s - loss: 23216602.0000 - mae: 3738.3420 - val_loss: 32515112.0000 - val_mae: 5110.7427\n",
            "Epoch 13/350\n",
            "3/3 - 0s - loss: 15586719.0000 - mae: 3149.8259 - val_loss: 28404040.0000 - val_mae: 4861.8457\n",
            "Epoch 14/350\n",
            "3/3 - 0s - loss: 35782124.0000 - mae: 3426.0217 - val_loss: 21986756.0000 - val_mae: 4260.7476\n",
            "Epoch 15/350\n",
            "3/3 - 0s - loss: 14014348.0000 - mae: 2975.4927 - val_loss: 18645138.0000 - val_mae: 3722.3789\n",
            "Epoch 16/350\n",
            "3/3 - 0s - loss: 14383857.0000 - mae: 2975.8418 - val_loss: 17523782.0000 - val_mae: 3296.8242\n",
            "Epoch 17/350\n",
            "3/3 - 0s - loss: 15528428.0000 - mae: 2996.3311 - val_loss: 24823770.0000 - val_mae: 3454.6406\n",
            "Epoch 18/350\n",
            "3/3 - 0s - loss: 19633666.0000 - mae: 3433.5144 - val_loss: 26363434.0000 - val_mae: 3615.0383\n",
            "Epoch 19/350\n",
            "3/3 - 0s - loss: 19341838.0000 - mae: 3447.8481 - val_loss: 24669824.0000 - val_mae: 3617.6702\n",
            "Epoch 20/350\n",
            "3/3 - 0s - loss: 15373171.0000 - mae: 3110.1697 - val_loss: 19532126.0000 - val_mae: 3814.8489\n",
            "Epoch 21/350\n",
            "3/3 - 0s - loss: 13346025.0000 - mae: 2909.4553 - val_loss: 19015600.0000 - val_mae: 4031.9910\n",
            "Epoch 22/350\n",
            "3/3 - 0s - loss: 13657615.0000 - mae: 3003.6931 - val_loss: 19548280.0000 - val_mae: 3945.6819\n",
            "Epoch 23/350\n",
            "3/3 - 0s - loss: 14159772.0000 - mae: 3040.7717 - val_loss: 18332938.0000 - val_mae: 3765.2009\n",
            "Epoch 24/350\n",
            "3/3 - 0s - loss: 13192092.0000 - mae: 2922.8435 - val_loss: 15296904.0000 - val_mae: 3179.5000\n",
            "Epoch 25/350\n",
            "3/3 - 0s - loss: 12958811.0000 - mae: 2735.3440 - val_loss: 15923508.0000 - val_mae: 3258.0198\n",
            "Epoch 26/350\n",
            "3/3 - 0s - loss: 12315525.0000 - mae: 2699.0032 - val_loss: 19070844.0000 - val_mae: 3517.4746\n",
            "Epoch 27/350\n",
            "3/3 - 0s - loss: 13945035.0000 - mae: 2761.8406 - val_loss: 18857452.0000 - val_mae: 3451.6121\n",
            "Epoch 28/350\n",
            "3/3 - 0s - loss: 13556343.0000 - mae: 2773.9500 - val_loss: 16477160.0000 - val_mae: 3274.4114\n",
            "Epoch 29/350\n",
            "3/3 - 0s - loss: 12667389.0000 - mae: 2732.7485 - val_loss: 15001197.0000 - val_mae: 2977.5664\n",
            "Epoch 30/350\n",
            "3/3 - 0s - loss: 12162024.0000 - mae: 2695.6392 - val_loss: 16845620.0000 - val_mae: 3350.1553\n",
            "Epoch 31/350\n",
            "3/3 - 0s - loss: 12181272.0000 - mae: 2704.5061 - val_loss: 15849273.0000 - val_mae: 3338.9636\n",
            "Epoch 32/350\n",
            "3/3 - 0s - loss: 11478403.0000 - mae: 2684.7917 - val_loss: 16788034.0000 - val_mae: 3526.1882\n",
            "Epoch 33/350\n",
            "3/3 - 0s - loss: 10810593.0000 - mae: 2582.7463 - val_loss: 15630615.0000 - val_mae: 3359.2527\n",
            "Epoch 34/350\n",
            "3/3 - 0s - loss: 10169445.0000 - mae: 2523.0981 - val_loss: 16701155.0000 - val_mae: 3433.3489\n",
            "Epoch 35/350\n",
            "3/3 - 0s - loss: 9977085.0000 - mae: 2459.9175 - val_loss: 30446694.0000 - val_mae: 4395.5981\n",
            "Epoch 36/350\n",
            "3/3 - 0s - loss: 13689611.0000 - mae: 2805.7190 - val_loss: 26242742.0000 - val_mae: 4070.8008\n",
            "Epoch 37/350\n",
            "3/3 - 0s - loss: 12550500.0000 - mae: 2797.3389 - val_loss: 21535198.0000 - val_mae: 3757.2957\n",
            "Epoch 38/350\n",
            "3/3 - 0s - loss: 19789422.0000 - mae: 3230.2812 - val_loss: 31103614.0000 - val_mae: 4368.6509\n",
            "Epoch 39/350\n",
            "3/3 - 0s - loss: 16791536.0000 - mae: 3012.3970 - val_loss: 22840502.0000 - val_mae: 4010.4304\n",
            "Epoch 40/350\n",
            "3/3 - 0s - loss: 14895511.0000 - mae: 3016.7314 - val_loss: 13257809.0000 - val_mae: 2787.9880\n",
            "Epoch 41/350\n",
            "3/3 - 0s - loss: 29029570.0000 - mae: 3389.8208 - val_loss: 10076447.0000 - val_mae: 2676.7837\n",
            "Epoch 42/350\n",
            "3/3 - 0s - loss: 29885550.0000 - mae: 3714.9622 - val_loss: 39477956.0000 - val_mae: 4391.3418\n",
            "Epoch 43/350\n",
            "3/3 - 0s - loss: 19213348.0000 - mae: 3388.6750 - val_loss: 49819472.0000 - val_mae: 5975.7539\n",
            "Epoch 44/350\n",
            "3/3 - 0s - loss: 27997054.0000 - mae: 3888.8445 - val_loss: 24899282.0000 - val_mae: 4384.0923\n",
            "Epoch 45/350\n",
            "3/3 - 0s - loss: 27940912.0000 - mae: 4119.6406 - val_loss: 25921462.0000 - val_mae: 4445.9399\n",
            "Epoch 46/350\n",
            "3/3 - 0s - loss: 16372788.0000 - mae: 3277.0281 - val_loss: 22824944.0000 - val_mae: 4376.4395\n",
            "Epoch 47/350\n",
            "3/3 - 0s - loss: 14833592.0000 - mae: 3078.3359 - val_loss: 16042960.0000 - val_mae: 3575.6433\n",
            "Epoch 48/350\n",
            "3/3 - 0s - loss: 14253699.0000 - mae: 2938.8098 - val_loss: 16490115.0000 - val_mae: 3256.0574\n",
            "Epoch 49/350\n",
            "3/3 - 0s - loss: 12928453.0000 - mae: 2791.9395 - val_loss: 15150835.0000 - val_mae: 3412.1204\n",
            "Epoch 50/350\n",
            "3/3 - 0s - loss: 11801819.0000 - mae: 2715.3765 - val_loss: 14990584.0000 - val_mae: 3544.3547\n",
            "Epoch 51/350\n",
            "3/3 - 0s - loss: 12263208.0000 - mae: 2750.2400 - val_loss: 14560829.0000 - val_mae: 3352.6895\n",
            "Epoch 52/350\n",
            "3/3 - 0s - loss: 12364873.0000 - mae: 2747.7849 - val_loss: 12416716.0000 - val_mae: 2886.9309\n",
            "Epoch 53/350\n",
            "3/3 - 0s - loss: 10060731.0000 - mae: 2476.3655 - val_loss: 12581264.0000 - val_mae: 2870.5378\n",
            "Epoch 54/350\n",
            "3/3 - 0s - loss: 9330705.0000 - mae: 2410.2485 - val_loss: 12126303.0000 - val_mae: 2751.8350\n",
            "Epoch 55/350\n",
            "3/3 - 0s - loss: 9169781.0000 - mae: 2430.3938 - val_loss: 12961256.0000 - val_mae: 2586.6357\n",
            "Epoch 56/350\n",
            "3/3 - 0s - loss: 9389300.0000 - mae: 2453.5020 - val_loss: 12886351.0000 - val_mae: 2713.5381\n",
            "Epoch 57/350\n",
            "3/3 - 0s - loss: 8930940.0000 - mae: 2378.7974 - val_loss: 12318799.0000 - val_mae: 2558.6174\n",
            "Epoch 58/350\n",
            "3/3 - 0s - loss: 8760112.0000 - mae: 2358.0718 - val_loss: 11874936.0000 - val_mae: 2492.5378\n",
            "Epoch 59/350\n",
            "3/3 - 0s - loss: 8889204.0000 - mae: 2355.5408 - val_loss: 12682157.0000 - val_mae: 2734.8311\n",
            "Epoch 60/350\n",
            "3/3 - 0s - loss: 8939108.0000 - mae: 2270.9924 - val_loss: 11997049.0000 - val_mae: 2627.8225\n",
            "Epoch 61/350\n",
            "3/3 - 0s - loss: 9091067.0000 - mae: 2300.1323 - val_loss: 11641247.0000 - val_mae: 2632.1111\n",
            "Epoch 62/350\n",
            "3/3 - 0s - loss: 10821524.0000 - mae: 2451.8328 - val_loss: 8400852.0000 - val_mae: 2253.0908\n",
            "Epoch 63/350\n",
            "3/3 - 0s - loss: 17664912.0000 - mae: 3122.4419 - val_loss: 18141978.0000 - val_mae: 3168.5735\n",
            "Epoch 64/350\n",
            "3/3 - 0s - loss: 14308559.0000 - mae: 2891.0183 - val_loss: 18943374.0000 - val_mae: 3748.8328\n",
            "Epoch 65/350\n",
            "3/3 - 0s - loss: 13369923.0000 - mae: 2770.9666 - val_loss: 20378602.0000 - val_mae: 3866.1113\n",
            "Epoch 66/350\n",
            "3/3 - 0s - loss: 13396652.0000 - mae: 2795.5437 - val_loss: 16177376.0000 - val_mae: 3327.5469\n",
            "Epoch 67/350\n",
            "3/3 - 0s - loss: 11459432.0000 - mae: 2621.3152 - val_loss: 15098779.0000 - val_mae: 3201.9915\n",
            "Epoch 68/350\n",
            "3/3 - 0s - loss: 10992292.0000 - mae: 2602.8074 - val_loss: 15821789.0000 - val_mae: 3389.4189\n",
            "Epoch 69/350\n",
            "3/3 - 0s - loss: 10825971.0000 - mae: 2483.7600 - val_loss: 15157075.0000 - val_mae: 3056.3396\n",
            "Epoch 70/350\n",
            "3/3 - 0s - loss: 9905508.0000 - mae: 2417.5173 - val_loss: 12837415.0000 - val_mae: 2619.2627\n",
            "Epoch 71/350\n",
            "3/3 - 0s - loss: 8445165.0000 - mae: 2240.5842 - val_loss: 8852253.0000 - val_mae: 2237.2417\n",
            "Epoch 72/350\n",
            "3/3 - 0s - loss: 8494187.0000 - mae: 2319.5320 - val_loss: 9289521.0000 - val_mae: 2418.9407\n",
            "Epoch 73/350\n",
            "3/3 - 0s - loss: 9231267.0000 - mae: 2378.1277 - val_loss: 9450123.0000 - val_mae: 2446.1306\n",
            "Epoch 74/350\n",
            "3/3 - 0s - loss: 8634837.0000 - mae: 2219.9028 - val_loss: 10756218.0000 - val_mae: 2622.2500\n",
            "Epoch 75/350\n",
            "3/3 - 0s - loss: 8213106.0000 - mae: 2212.2776 - val_loss: 10594611.0000 - val_mae: 2622.5525\n",
            "Epoch 76/350\n",
            "3/3 - 0s - loss: 8388068.0000 - mae: 2179.7725 - val_loss: 12736785.0000 - val_mae: 2781.7136\n",
            "Epoch 77/350\n",
            "3/3 - 0s - loss: 8250680.0000 - mae: 2210.0791 - val_loss: 12043081.0000 - val_mae: 2811.7871\n",
            "Epoch 78/350\n",
            "3/3 - 0s - loss: 8293346.5000 - mae: 2225.6570 - val_loss: 11165916.0000 - val_mae: 2707.9666\n",
            "Epoch 79/350\n",
            "3/3 - 0s - loss: 8062024.0000 - mae: 2178.7646 - val_loss: 10925885.0000 - val_mae: 2672.9104\n",
            "Epoch 80/350\n",
            "3/3 - 0s - loss: 7571368.5000 - mae: 2134.5808 - val_loss: 9952736.0000 - val_mae: 2571.5696\n",
            "Epoch 81/350\n",
            "3/3 - 0s - loss: 7755546.0000 - mae: 2146.2673 - val_loss: 11743741.0000 - val_mae: 2702.4785\n",
            "Epoch 82/350\n",
            "3/3 - 0s - loss: 8174652.0000 - mae: 2222.8191 - val_loss: 12447555.0000 - val_mae: 2726.3350\n",
            "Epoch 83/350\n",
            "3/3 - 0s - loss: 8330249.5000 - mae: 2212.0730 - val_loss: 11393083.0000 - val_mae: 2589.7786\n",
            "Epoch 84/350\n",
            "3/3 - 0s - loss: 7795474.5000 - mae: 2128.1436 - val_loss: 10531141.0000 - val_mae: 2488.9688\n",
            "Epoch 85/350\n",
            "3/3 - 0s - loss: 7569890.5000 - mae: 2109.0745 - val_loss: 10111873.0000 - val_mae: 2440.3564\n",
            "Epoch 86/350\n",
            "3/3 - 0s - loss: 7181800.5000 - mae: 2057.3735 - val_loss: 14867981.0000 - val_mae: 2947.5037\n",
            "Epoch 87/350\n",
            "3/3 - 0s - loss: 7821614.0000 - mae: 2107.2605 - val_loss: 14921520.0000 - val_mae: 2945.7175\n",
            "Epoch 88/350\n",
            "3/3 - 0s - loss: 7897156.0000 - mae: 2160.0022 - val_loss: 15359480.0000 - val_mae: 3026.1492\n",
            "Epoch 89/350\n",
            "3/3 - 0s - loss: 7595044.0000 - mae: 2091.1084 - val_loss: 14843800.0000 - val_mae: 2950.5583\n",
            "Epoch 90/350\n",
            "3/3 - 0s - loss: 7554087.5000 - mae: 2045.9801 - val_loss: 14841204.0000 - val_mae: 2902.4561\n",
            "Epoch 91/350\n",
            "3/3 - 0s - loss: 7215173.5000 - mae: 2030.3809 - val_loss: 14266368.0000 - val_mae: 2842.5520\n",
            "Epoch 92/350\n",
            "3/3 - 0s - loss: 7091797.5000 - mae: 2046.0718 - val_loss: 13590619.0000 - val_mae: 2846.7188\n",
            "Epoch 93/350\n",
            "3/3 - 0s - loss: 7137410.0000 - mae: 2057.8572 - val_loss: 8084795.5000 - val_mae: 2205.6699\n",
            "Epoch 94/350\n",
            "3/3 - 0s - loss: 6967132.5000 - mae: 2099.9456 - val_loss: 8297954.5000 - val_mae: 2305.8022\n",
            "Epoch 95/350\n",
            "3/3 - 0s - loss: 7217223.5000 - mae: 2091.5674 - val_loss: 13902224.0000 - val_mae: 2811.7542\n",
            "Epoch 96/350\n",
            "3/3 - 0s - loss: 7611396.0000 - mae: 2098.0193 - val_loss: 12985227.0000 - val_mae: 2680.4465\n",
            "Epoch 97/350\n",
            "3/3 - 0s - loss: 8425267.0000 - mae: 2231.5999 - val_loss: 13257511.0000 - val_mae: 2806.5696\n",
            "Epoch 98/350\n",
            "3/3 - 0s - loss: 8611044.0000 - mae: 2323.4309 - val_loss: 12931405.0000 - val_mae: 2808.9482\n",
            "Epoch 99/350\n",
            "3/3 - 0s - loss: 8665931.0000 - mae: 2284.5549 - val_loss: 12476421.0000 - val_mae: 2686.7107\n",
            "Epoch 100/350\n",
            "3/3 - 0s - loss: 8278832.0000 - mae: 2266.0759 - val_loss: 12456467.0000 - val_mae: 2717.2063\n",
            "Epoch 101/350\n",
            "3/3 - 0s - loss: 8155216.0000 - mae: 2259.7231 - val_loss: 11526815.0000 - val_mae: 2733.9099\n",
            "Epoch 102/350\n",
            "3/3 - 0s - loss: 7956116.5000 - mae: 2234.2114 - val_loss: 11203829.0000 - val_mae: 2755.7659\n",
            "Epoch 103/350\n",
            "3/3 - 0s - loss: 7800314.5000 - mae: 2245.1643 - val_loss: 11123839.0000 - val_mae: 2791.8430\n",
            "Epoch 104/350\n",
            "3/3 - 0s - loss: 7801189.5000 - mae: 2234.4460 - val_loss: 11259625.0000 - val_mae: 2746.2185\n",
            "Epoch 105/350\n",
            "3/3 - 0s - loss: 7926564.0000 - mae: 2219.2744 - val_loss: 11149457.0000 - val_mae: 2762.0066\n",
            "Epoch 106/350\n",
            "3/3 - 0s - loss: 7703696.5000 - mae: 2202.7290 - val_loss: 11041266.0000 - val_mae: 2802.9177\n",
            "Epoch 107/350\n",
            "3/3 - 0s - loss: 7805708.0000 - mae: 2221.7583 - val_loss: 11137275.0000 - val_mae: 2820.7473\n",
            "Epoch 108/350\n",
            "3/3 - 0s - loss: 7690770.5000 - mae: 2200.8760 - val_loss: 11131237.0000 - val_mae: 2799.3174\n",
            "Epoch 109/350\n",
            "3/3 - 0s - loss: 7773813.5000 - mae: 2185.4116 - val_loss: 11398016.0000 - val_mae: 2808.5447\n",
            "Epoch 110/350\n",
            "3/3 - 0s - loss: 7664596.0000 - mae: 2188.5796 - val_loss: 11322119.0000 - val_mae: 2814.0198\n",
            "Epoch 111/350\n",
            "3/3 - 0s - loss: 7550857.5000 - mae: 2191.2810 - val_loss: 11304017.0000 - val_mae: 2827.6741\n",
            "Epoch 112/350\n",
            "3/3 - 0s - loss: 7661592.5000 - mae: 2189.2822 - val_loss: 10893072.0000 - val_mae: 2735.4336\n",
            "Epoch 113/350\n",
            "3/3 - 0s - loss: 7648988.0000 - mae: 2193.9233 - val_loss: 10873515.0000 - val_mae: 2737.3123\n",
            "Epoch 114/350\n",
            "3/3 - 0s - loss: 7608942.0000 - mae: 2185.3672 - val_loss: 10970280.0000 - val_mae: 2745.3738\n",
            "Epoch 115/350\n",
            "3/3 - 0s - loss: 7797751.5000 - mae: 2191.8784 - val_loss: 11179541.0000 - val_mae: 2756.3816\n",
            "Epoch 116/350\n",
            "3/3 - 0s - loss: 8045474.5000 - mae: 2225.6021 - val_loss: 11306599.0000 - val_mae: 2777.8184\n",
            "Epoch 117/350\n",
            "3/3 - 0s - loss: 7680768.0000 - mae: 2196.6514 - val_loss: 11636145.0000 - val_mae: 2788.0090\n",
            "Epoch 118/350\n",
            "3/3 - 0s - loss: 7699286.5000 - mae: 2175.6228 - val_loss: 12098288.0000 - val_mae: 2806.1172\n",
            "Epoch 119/350\n",
            "3/3 - 0s - loss: 8008549.5000 - mae: 2152.0154 - val_loss: 11235492.0000 - val_mae: 2767.8298\n",
            "Epoch 120/350\n",
            "3/3 - 0s - loss: 7799991.5000 - mae: 2181.4990 - val_loss: 11339725.0000 - val_mae: 2790.2988\n",
            "Epoch 121/350\n",
            "3/3 - 0s - loss: 7672055.5000 - mae: 2220.6714 - val_loss: 11388843.0000 - val_mae: 2810.4480\n",
            "Epoch 122/350\n",
            "3/3 - 0s - loss: 7555816.5000 - mae: 2169.8955 - val_loss: 12102781.0000 - val_mae: 2827.3503\n",
            "Epoch 123/350\n",
            "3/3 - 0s - loss: 7768374.5000 - mae: 2127.7219 - val_loss: 11768491.0000 - val_mae: 2843.6719\n",
            "Epoch 124/350\n",
            "3/3 - 0s - loss: 7616136.5000 - mae: 2135.4075 - val_loss: 11565869.0000 - val_mae: 2864.9124\n",
            "Epoch 125/350\n",
            "3/3 - 0s - loss: 7593750.0000 - mae: 2157.9536 - val_loss: 11378147.0000 - val_mae: 2850.6340\n",
            "Epoch 126/350\n",
            "3/3 - 0s - loss: 7303420.0000 - mae: 2119.6733 - val_loss: 11423368.0000 - val_mae: 2864.5007\n",
            "Epoch 127/350\n",
            "3/3 - 0s - loss: 7447869.5000 - mae: 2097.3843 - val_loss: 11397285.0000 - val_mae: 2853.5447\n",
            "Epoch 128/350\n",
            "3/3 - 0s - loss: 7510856.0000 - mae: 2094.3625 - val_loss: 11106565.0000 - val_mae: 2855.2825\n",
            "Epoch 129/350\n",
            "3/3 - 0s - loss: 7548716.5000 - mae: 2142.2144 - val_loss: 11240211.0000 - val_mae: 2878.8201\n",
            "Epoch 130/350\n",
            "3/3 - 0s - loss: 7291877.5000 - mae: 2123.3442 - val_loss: 11095835.0000 - val_mae: 2862.0938\n",
            "Epoch 131/350\n",
            "3/3 - 0s - loss: 7207918.0000 - mae: 2092.1819 - val_loss: 11265131.0000 - val_mae: 2864.5684\n",
            "Epoch 132/350\n",
            "3/3 - 0s - loss: 7326278.0000 - mae: 2094.5593 - val_loss: 11187187.0000 - val_mae: 2876.3547\n",
            "Epoch 133/350\n",
            "3/3 - 0s - loss: 7235280.5000 - mae: 2120.5618 - val_loss: 11201120.0000 - val_mae: 2891.4924\n",
            "Epoch 134/350\n",
            "3/3 - 0s - loss: 7382445.5000 - mae: 2125.1404 - val_loss: 11264476.0000 - val_mae: 2884.3398\n",
            "Epoch 135/350\n",
            "3/3 - 0s - loss: 7267681.5000 - mae: 2093.1982 - val_loss: 11358123.0000 - val_mae: 2873.6953\n",
            "Epoch 136/350\n",
            "3/3 - 0s - loss: 7298188.0000 - mae: 2087.9995 - val_loss: 11245507.0000 - val_mae: 2879.1458\n",
            "Epoch 137/350\n",
            "3/3 - 0s - loss: 7254225.5000 - mae: 2107.2041 - val_loss: 11233679.0000 - val_mae: 2887.3918\n",
            "Epoch 138/350\n",
            "3/3 - 0s - loss: 7159758.5000 - mae: 2112.5293 - val_loss: 11087849.0000 - val_mae: 2867.7161\n",
            "Epoch 139/350\n",
            "3/3 - 0s - loss: 7229498.5000 - mae: 2085.3713 - val_loss: 11062104.0000 - val_mae: 2852.9746\n",
            "Epoch 140/350\n",
            "3/3 - 0s - loss: 7218297.5000 - mae: 2078.6658 - val_loss: 10986088.0000 - val_mae: 2850.4209\n",
            "Epoch 141/350\n",
            "3/3 - 0s - loss: 7036988.0000 - mae: 2103.8379 - val_loss: 10928349.0000 - val_mae: 2850.8445\n",
            "Epoch 142/350\n",
            "3/3 - 0s - loss: 7082331.5000 - mae: 2117.2451 - val_loss: 10875681.0000 - val_mae: 2838.8086\n",
            "Epoch 143/350\n",
            "3/3 - 0s - loss: 7046008.5000 - mae: 2081.8977 - val_loss: 11157637.0000 - val_mae: 2814.4197\n",
            "Epoch 144/350\n",
            "3/3 - 0s - loss: 7169349.5000 - mae: 2083.0500 - val_loss: 11100547.0000 - val_mae: 2811.7468\n",
            "Epoch 145/350\n",
            "3/3 - 0s - loss: 7125281.5000 - mae: 2075.6306 - val_loss: 10937881.0000 - val_mae: 2826.8376\n",
            "Epoch 146/350\n",
            "3/3 - 0s - loss: 7337538.5000 - mae: 2148.8535 - val_loss: 10961071.0000 - val_mae: 2830.9114\n",
            "Epoch 147/350\n",
            "3/3 - 0s - loss: 7374132.0000 - mae: 2107.8411 - val_loss: 11161039.0000 - val_mae: 2797.5959\n",
            "Epoch 148/350\n",
            "3/3 - 0s - loss: 7227233.5000 - mae: 2075.2163 - val_loss: 10892718.0000 - val_mae: 2797.5449\n",
            "Epoch 149/350\n",
            "3/3 - 0s - loss: 7157412.5000 - mae: 2092.0688 - val_loss: 10725339.0000 - val_mae: 2814.7537\n",
            "Epoch 150/350\n",
            "3/3 - 0s - loss: 7090374.5000 - mae: 2108.6262 - val_loss: 10755059.0000 - val_mae: 2812.6873\n",
            "Epoch 151/350\n",
            "3/3 - 0s - loss: 7275390.5000 - mae: 2103.4563 - val_loss: 11073717.0000 - val_mae: 2798.6125\n",
            "Epoch 152/350\n",
            "3/3 - 0s - loss: 6998514.0000 - mae: 2058.6660 - val_loss: 10824809.0000 - val_mae: 2810.6492\n",
            "Epoch 153/350\n",
            "3/3 - 0s - loss: 6938520.0000 - mae: 2093.7563 - val_loss: 10824702.0000 - val_mae: 2830.4309\n",
            "Epoch 154/350\n",
            "3/3 - 0s - loss: 7221123.5000 - mae: 2136.5312 - val_loss: 10722922.0000 - val_mae: 2823.6145\n",
            "Epoch 155/350\n",
            "3/3 - 0s - loss: 7023217.5000 - mae: 2103.5288 - val_loss: 11331657.0000 - val_mae: 2793.1570\n",
            "Epoch 156/350\n",
            "3/3 - 0s - loss: 7170511.5000 - mae: 2069.8926 - val_loss: 10846064.0000 - val_mae: 2803.0312\n",
            "Epoch 157/350\n",
            "3/3 - 0s - loss: 6999868.0000 - mae: 2081.9180 - val_loss: 10699601.0000 - val_mae: 2812.3850\n",
            "Epoch 158/350\n",
            "3/3 - 0s - loss: 7111581.5000 - mae: 2110.3030 - val_loss: 10627757.0000 - val_mae: 2801.3923\n",
            "Epoch 159/350\n",
            "3/3 - 0s - loss: 6941825.5000 - mae: 2085.4116 - val_loss: 10724829.0000 - val_mae: 2780.4336\n",
            "Epoch 160/350\n",
            "3/3 - 0s - loss: 6893951.5000 - mae: 2066.1987 - val_loss: 11113953.0000 - val_mae: 2759.5129\n",
            "Epoch 161/350\n",
            "3/3 - 0s - loss: 7172820.0000 - mae: 2070.0159 - val_loss: 10623548.0000 - val_mae: 2779.3301\n",
            "Epoch 162/350\n",
            "3/3 - 0s - loss: 6925293.5000 - mae: 2068.5627 - val_loss: 10662847.0000 - val_mae: 2794.1648\n",
            "Epoch 163/350\n",
            "3/3 - 0s - loss: 7212905.5000 - mae: 2123.0720 - val_loss: 10613006.0000 - val_mae: 2780.5264\n",
            "Epoch 164/350\n",
            "3/3 - 0s - loss: 6952848.0000 - mae: 2071.2249 - val_loss: 10803320.0000 - val_mae: 2760.9558\n",
            "Epoch 165/350\n",
            "3/3 - 0s - loss: 6838150.0000 - mae: 2054.8154 - val_loss: 10772175.0000 - val_mae: 2762.1145\n",
            "Epoch 166/350\n",
            "3/3 - 0s - loss: 7002961.5000 - mae: 2049.2312 - val_loss: 10561069.0000 - val_mae: 2773.8835\n",
            "Epoch 167/350\n",
            "3/3 - 0s - loss: 6865611.5000 - mae: 2068.6948 - val_loss: 10571960.0000 - val_mae: 2784.7952\n",
            "Epoch 168/350\n",
            "3/3 - 0s - loss: 6917131.5000 - mae: 2071.2725 - val_loss: 10576870.0000 - val_mae: 2781.9834\n",
            "Epoch 169/350\n",
            "3/3 - 0s - loss: 7179610.5000 - mae: 2066.1772 - val_loss: 10581101.0000 - val_mae: 2772.0850\n",
            "Epoch 170/350\n",
            "3/3 - 0s - loss: 6855808.0000 - mae: 2050.6343 - val_loss: 10449852.0000 - val_mae: 2775.5391\n",
            "Epoch 171/350\n",
            "3/3 - 0s - loss: 6999032.0000 - mae: 2078.2400 - val_loss: 10423007.0000 - val_mae: 2775.3674\n",
            "Epoch 172/350\n",
            "3/3 - 0s - loss: 6772192.5000 - mae: 2080.3506 - val_loss: 10618886.0000 - val_mae: 2757.4355\n",
            "Epoch 173/350\n",
            "3/3 - 0s - loss: 6862557.5000 - mae: 2042.3776 - val_loss: 10840961.0000 - val_mae: 2758.1660\n",
            "Epoch 174/350\n",
            "3/3 - 0s - loss: 7053012.0000 - mae: 2062.6555 - val_loss: 10667341.0000 - val_mae: 2782.0110\n",
            "Epoch 175/350\n",
            "3/3 - 0s - loss: 6865155.5000 - mae: 2101.0691 - val_loss: 10579001.0000 - val_mae: 2783.4348\n",
            "Epoch 176/350\n",
            "3/3 - 0s - loss: 6848260.0000 - mae: 2049.1641 - val_loss: 10803388.0000 - val_mae: 2760.9719\n",
            "Epoch 177/350\n",
            "3/3 - 0s - loss: 6776961.5000 - mae: 2033.9608 - val_loss: 10658431.0000 - val_mae: 2751.5730\n",
            "Epoch 178/350\n",
            "3/3 - 0s - loss: 6633005.5000 - mae: 2028.7423 - val_loss: 10267867.0000 - val_mae: 2760.9717\n",
            "Epoch 179/350\n",
            "3/3 - 0s - loss: 6851691.5000 - mae: 2066.2412 - val_loss: 10317515.0000 - val_mae: 2768.5056\n",
            "Epoch 180/350\n",
            "3/3 - 0s - loss: 7045698.0000 - mae: 2061.4873 - val_loss: 10387357.0000 - val_mae: 2755.1045\n",
            "Epoch 181/350\n",
            "3/3 - 0s - loss: 6853985.5000 - mae: 2034.6378 - val_loss: 10275605.0000 - val_mae: 2758.8064\n",
            "Epoch 182/350\n",
            "3/3 - 0s - loss: 6545092.0000 - mae: 2046.4071 - val_loss: 10280783.0000 - val_mae: 2766.1824\n",
            "Epoch 183/350\n",
            "3/3 - 0s - loss: 6701144.5000 - mae: 2060.7844 - val_loss: 10293031.0000 - val_mae: 2764.1277\n",
            "Epoch 184/350\n",
            "3/3 - 0s - loss: 6756385.5000 - mae: 2041.3969 - val_loss: 10366140.0000 - val_mae: 2763.3889\n",
            "Epoch 185/350\n",
            "3/3 - 0s - loss: 6680097.5000 - mae: 2028.5624 - val_loss: 10553551.0000 - val_mae: 2765.2708\n",
            "Epoch 186/350\n",
            "3/3 - 0s - loss: 6737516.0000 - mae: 2037.5698 - val_loss: 10524959.0000 - val_mae: 2771.3171\n",
            "Epoch 187/350\n",
            "3/3 - 0s - loss: 6630005.5000 - mae: 2047.4623 - val_loss: 10526353.0000 - val_mae: 2768.4119\n",
            "Epoch 188/350\n",
            "3/3 - 0s - loss: 6858830.5000 - mae: 2045.0778 - val_loss: 10469392.0000 - val_mae: 2766.4736\n",
            "Epoch 189/350\n",
            "3/3 - 0s - loss: 6805966.5000 - mae: 2038.0946 - val_loss: 10530275.0000 - val_mae: 2758.8213\n",
            "Epoch 190/350\n",
            "3/3 - 0s - loss: 6571570.5000 - mae: 2031.7488 - val_loss: 10328539.0000 - val_mae: 2762.1992\n",
            "Epoch 191/350\n",
            "3/3 - 0s - loss: 6589260.5000 - mae: 2059.6785 - val_loss: 10304959.0000 - val_mae: 2760.2676\n",
            "Epoch 192/350\n",
            "3/3 - 0s - loss: 6657872.0000 - mae: 2056.6641 - val_loss: 10409241.0000 - val_mae: 2751.8430\n",
            "Epoch 193/350\n",
            "3/3 - 0s - loss: 6647618.5000 - mae: 2032.9915 - val_loss: 10781473.0000 - val_mae: 2746.0413\n",
            "Epoch 194/350\n",
            "3/3 - 0s - loss: 6661905.5000 - mae: 2006.6710 - val_loss: 10250381.0000 - val_mae: 2761.0564\n",
            "Epoch 195/350\n",
            "3/3 - 0s - loss: 6837258.5000 - mae: 2054.0569 - val_loss: 10252635.0000 - val_mae: 2764.0234\n",
            "Epoch 196/350\n",
            "3/3 - 0s - loss: 6793314.0000 - mae: 2066.9363 - val_loss: 10502896.0000 - val_mae: 2743.1609\n",
            "Epoch 197/350\n",
            "3/3 - 0s - loss: 6652850.0000 - mae: 2012.6764 - val_loss: 10592264.0000 - val_mae: 2739.9177\n",
            "Epoch 198/350\n",
            "3/3 - 0s - loss: 6700233.5000 - mae: 2052.1184 - val_loss: 10426595.0000 - val_mae: 2737.9021\n",
            "Epoch 199/350\n",
            "3/3 - 0s - loss: 6613505.5000 - mae: 2036.7729 - val_loss: 10407185.0000 - val_mae: 2710.1643\n",
            "Epoch 200/350\n",
            "3/3 - 0s - loss: 6668367.5000 - mae: 2022.1089 - val_loss: 10040932.0000 - val_mae: 2699.5303\n",
            "Epoch 201/350\n",
            "3/3 - 0s - loss: 6584332.0000 - mae: 2005.8151 - val_loss: 9955689.0000 - val_mae: 2694.6775\n",
            "Epoch 202/350\n",
            "3/3 - 0s - loss: 6854162.5000 - mae: 2015.2727 - val_loss: 9986015.0000 - val_mae: 2702.8108\n",
            "Epoch 203/350\n",
            "3/3 - 0s - loss: 6639232.0000 - mae: 2011.4932 - val_loss: 10201867.0000 - val_mae: 2707.2556\n",
            "Epoch 204/350\n",
            "3/3 - 0s - loss: 6476910.0000 - mae: 2018.2386 - val_loss: 10242101.0000 - val_mae: 2713.7112\n",
            "Epoch 205/350\n",
            "3/3 - 0s - loss: 6693502.0000 - mae: 2020.2837 - val_loss: 10326023.0000 - val_mae: 2707.3445\n",
            "Epoch 206/350\n",
            "3/3 - 0s - loss: 6626391.5000 - mae: 2012.6853 - val_loss: 10347395.0000 - val_mae: 2707.1287\n",
            "Epoch 207/350\n",
            "3/3 - 0s - loss: 6602192.0000 - mae: 2046.9799 - val_loss: 10318204.0000 - val_mae: 2730.8684\n",
            "Epoch 208/350\n",
            "3/3 - 0s - loss: 6433553.5000 - mae: 2029.1381 - val_loss: 10480900.0000 - val_mae: 2739.2419\n",
            "Epoch 209/350\n",
            "3/3 - 0s - loss: 6367829.5000 - mae: 1978.4700 - val_loss: 10190922.0000 - val_mae: 2741.1523\n",
            "Epoch 210/350\n",
            "3/3 - 0s - loss: 6337965.5000 - mae: 1986.4784 - val_loss: 10090098.0000 - val_mae: 2759.0840\n",
            "Epoch 211/350\n",
            "3/3 - 0s - loss: 6320534.0000 - mae: 2001.4127 - val_loss: 10174689.0000 - val_mae: 2750.0530\n",
            "Epoch 212/350\n",
            "3/3 - 0s - loss: 6155592.5000 - mae: 1983.7153 - val_loss: 10567320.0000 - val_mae: 2746.0508\n",
            "Epoch 213/350\n",
            "3/3 - 0s - loss: 6448288.0000 - mae: 1982.9557 - val_loss: 10698134.0000 - val_mae: 2758.2996\n",
            "Epoch 214/350\n",
            "3/3 - 0s - loss: 6209657.5000 - mae: 1999.1246 - val_loss: 10342311.0000 - val_mae: 2761.0500\n",
            "Epoch 215/350\n",
            "3/3 - 0s - loss: 6146998.5000 - mae: 2010.6011 - val_loss: 10153337.0000 - val_mae: 2748.0430\n",
            "Epoch 216/350\n",
            "3/3 - 0s - loss: 6237252.5000 - mae: 1983.9640 - val_loss: 10383983.0000 - val_mae: 2720.6699\n",
            "Epoch 217/350\n",
            "3/3 - 0s - loss: 6127804.5000 - mae: 1963.5001 - val_loss: 10082723.0000 - val_mae: 2736.9934\n",
            "Epoch 218/350\n",
            "3/3 - 0s - loss: 6395222.0000 - mae: 2030.0470 - val_loss: 10196410.0000 - val_mae: 2748.4084\n",
            "Epoch 219/350\n",
            "3/3 - 0s - loss: 6212837.5000 - mae: 1998.4237 - val_loss: 10815367.0000 - val_mae: 2728.7390\n",
            "Epoch 220/350\n",
            "3/3 - 0s - loss: 6325126.5000 - mae: 1987.5620 - val_loss: 10447565.0000 - val_mae: 2737.9055\n",
            "Epoch 221/350\n",
            "3/3 - 0s - loss: 6308928.0000 - mae: 1979.6504 - val_loss: 10511261.0000 - val_mae: 2741.9871\n",
            "Epoch 222/350\n",
            "3/3 - 0s - loss: 6126809.5000 - mae: 1987.0405 - val_loss: 10299535.0000 - val_mae: 2739.2773\n",
            "Epoch 223/350\n",
            "3/3 - 0s - loss: 6251426.0000 - mae: 2007.1534 - val_loss: 10246715.0000 - val_mae: 2724.4412\n",
            "Epoch 224/350\n",
            "3/3 - 0s - loss: 5999574.0000 - mae: 1973.4138 - val_loss: 10139570.0000 - val_mae: 2731.6497\n",
            "Epoch 225/350\n",
            "3/3 - 0s - loss: 6127040.0000 - mae: 1984.1182 - val_loss: 10189904.0000 - val_mae: 2719.4661\n",
            "Epoch 226/350\n",
            "3/3 - 0s - loss: 6231032.5000 - mae: 1986.2386 - val_loss: 10034593.0000 - val_mae: 2720.6838\n",
            "Epoch 227/350\n",
            "3/3 - 0s - loss: 6277288.0000 - mae: 1978.9712 - val_loss: 10543799.0000 - val_mae: 2715.9866\n",
            "Epoch 228/350\n",
            "3/3 - 0s - loss: 6078200.5000 - mae: 1951.2279 - val_loss: 10220705.0000 - val_mae: 2721.7371\n",
            "Epoch 229/350\n",
            "3/3 - 0s - loss: 6250728.0000 - mae: 1964.3375 - val_loss: 10122219.0000 - val_mae: 2718.2148\n",
            "Epoch 230/350\n",
            "3/3 - 0s - loss: 6122977.5000 - mae: 1974.2490 - val_loss: 10051769.0000 - val_mae: 2713.4612\n",
            "Epoch 231/350\n",
            "3/3 - 0s - loss: 6081821.5000 - mae: 1959.8884 - val_loss: 10269526.0000 - val_mae: 2702.9807\n",
            "Epoch 232/350\n",
            "3/3 - 0s - loss: 6159518.5000 - mae: 1947.6454 - val_loss: 10157192.0000 - val_mae: 2701.9846\n",
            "Epoch 233/350\n",
            "3/3 - 0s - loss: 5929478.0000 - mae: 1961.0424 - val_loss: 10160416.0000 - val_mae: 2710.6252\n",
            "Epoch 234/350\n",
            "3/3 - 0s - loss: 6100377.5000 - mae: 1981.9146 - val_loss: 10260695.0000 - val_mae: 2714.8411\n",
            "Epoch 235/350\n",
            "3/3 - 0s - loss: 5997270.5000 - mae: 1982.2030 - val_loss: 10438709.0000 - val_mae: 2714.5918\n",
            "Epoch 236/350\n",
            "3/3 - 0s - loss: 6421850.5000 - mae: 2001.8630 - val_loss: 10236531.0000 - val_mae: 2718.9678\n",
            "Epoch 237/350\n",
            "3/3 - 0s - loss: 7195649.5000 - mae: 2057.7073 - val_loss: 10160479.0000 - val_mae: 2704.6594\n",
            "Epoch 238/350\n",
            "3/3 - 0s - loss: 6815249.5000 - mae: 2016.5325 - val_loss: 9766733.0000 - val_mae: 2686.3799\n",
            "Epoch 239/350\n",
            "3/3 - 0s - loss: 6798226.0000 - mae: 2018.4207 - val_loss: 9643791.0000 - val_mae: 2665.7354\n",
            "Epoch 240/350\n",
            "3/3 - 0s - loss: 6970480.5000 - mae: 2010.8066 - val_loss: 9566208.0000 - val_mae: 2653.4736\n",
            "Epoch 241/350\n",
            "3/3 - 0s - loss: 6922496.0000 - mae: 1994.5177 - val_loss: 9399236.0000 - val_mae: 2642.6243\n",
            "Epoch 242/350\n",
            "3/3 - 0s - loss: 6776890.5000 - mae: 1976.7402 - val_loss: 9532317.0000 - val_mae: 2621.1174\n",
            "Epoch 243/350\n",
            "3/3 - 0s - loss: 6739404.0000 - mae: 2006.8618 - val_loss: 9538639.0000 - val_mae: 2622.2205\n",
            "Epoch 244/350\n",
            "3/3 - 0s - loss: 6782658.5000 - mae: 1987.9038 - val_loss: 9449388.0000 - val_mae: 2636.8474\n",
            "Epoch 245/350\n",
            "3/3 - 0s - loss: 6772578.5000 - mae: 1985.4552 - val_loss: 9531028.0000 - val_mae: 2630.0737\n",
            "Epoch 246/350\n",
            "3/3 - 0s - loss: 6821364.0000 - mae: 2002.6904 - val_loss: 9971269.0000 - val_mae: 2612.8320\n",
            "Epoch 247/350\n",
            "3/3 - 0s - loss: 6884200.0000 - mae: 2009.3910 - val_loss: 9629726.0000 - val_mae: 2612.6807\n",
            "Epoch 248/350\n",
            "3/3 - 0s - loss: 6717108.0000 - mae: 1982.9764 - val_loss: 9641053.0000 - val_mae: 2596.4482\n",
            "Epoch 249/350\n",
            "3/3 - 0s - loss: 6600330.5000 - mae: 1990.9248 - val_loss: 9772587.0000 - val_mae: 2576.4434\n",
            "Epoch 250/350\n",
            "3/3 - 0s - loss: 6902872.0000 - mae: 1997.0613 - val_loss: 9583036.0000 - val_mae: 2586.4016\n",
            "Epoch 251/350\n",
            "3/3 - 0s - loss: 6611150.0000 - mae: 1986.6188 - val_loss: 9752448.0000 - val_mae: 2584.8108\n",
            "Epoch 252/350\n",
            "3/3 - 0s - loss: 6696260.0000 - mae: 1981.9562 - val_loss: 9556005.0000 - val_mae: 2587.9128\n",
            "Epoch 253/350\n",
            "3/3 - 0s - loss: 6622772.5000 - mae: 1984.8142 - val_loss: 9451784.0000 - val_mae: 2590.7334\n",
            "Epoch 254/350\n",
            "3/3 - 0s - loss: 6572273.5000 - mae: 1969.1813 - val_loss: 9450739.0000 - val_mae: 2578.3867\n",
            "Epoch 255/350\n",
            "3/3 - 0s - loss: 6730538.5000 - mae: 1971.8223 - val_loss: 9472307.0000 - val_mae: 2569.8228\n",
            "Epoch 256/350\n",
            "3/3 - 0s - loss: 6492144.0000 - mae: 1963.4102 - val_loss: 9622103.0000 - val_mae: 2559.5713\n",
            "Epoch 257/350\n",
            "3/3 - 0s - loss: 6528666.5000 - mae: 1971.2395 - val_loss: 9543067.0000 - val_mae: 2552.1624\n",
            "Epoch 258/350\n",
            "3/3 - 0s - loss: 6509481.5000 - mae: 1967.0740 - val_loss: 9622380.0000 - val_mae: 2558.0859\n",
            "Epoch 259/350\n",
            "3/3 - 0s - loss: 6639302.0000 - mae: 1966.1364 - val_loss: 9557730.0000 - val_mae: 2549.6433\n",
            "Epoch 260/350\n",
            "3/3 - 0s - loss: 6707290.5000 - mae: 1964.7373 - val_loss: 9531341.0000 - val_mae: 2551.7998\n",
            "Epoch 261/350\n",
            "3/3 - 0s - loss: 6582962.5000 - mae: 1986.4600 - val_loss: 9477863.0000 - val_mae: 2538.1846\n",
            "Epoch 262/350\n",
            "3/3 - 0s - loss: 6681237.5000 - mae: 1978.2628 - val_loss: 9590020.0000 - val_mae: 2540.0820\n",
            "Epoch 263/350\n",
            "3/3 - 0s - loss: 6532355.5000 - mae: 1965.3060 - val_loss: 9692181.0000 - val_mae: 2550.8018\n",
            "Epoch 264/350\n",
            "3/3 - 0s - loss: 6564690.0000 - mae: 1979.5282 - val_loss: 9505020.0000 - val_mae: 2528.4211\n",
            "Epoch 265/350\n",
            "3/3 - 0s - loss: 6468852.5000 - mae: 1959.0544 - val_loss: 9266610.0000 - val_mae: 2522.4290\n",
            "Epoch 266/350\n",
            "3/3 - 0s - loss: 6589122.5000 - mae: 1963.9911 - val_loss: 9262245.0000 - val_mae: 2506.4482\n",
            "Epoch 267/350\n",
            "3/3 - 0s - loss: 6587412.5000 - mae: 1970.6515 - val_loss: 9360986.0000 - val_mae: 2521.7344\n",
            "Epoch 268/350\n",
            "3/3 - 0s - loss: 6516484.5000 - mae: 1951.7822 - val_loss: 9390992.0000 - val_mae: 2505.3564\n",
            "Epoch 269/350\n",
            "3/3 - 0s - loss: 6468983.5000 - mae: 1958.4852 - val_loss: 9298419.0000 - val_mae: 2485.0339\n",
            "Epoch 270/350\n",
            "3/3 - 0s - loss: 6489146.0000 - mae: 1940.6013 - val_loss: 9295352.0000 - val_mae: 2488.9727\n",
            "Epoch 271/350\n",
            "3/3 - 0s - loss: 6567209.5000 - mae: 1977.4763 - val_loss: 9295580.0000 - val_mae: 2482.5540\n",
            "Epoch 272/350\n",
            "3/3 - 0s - loss: 6581985.5000 - mae: 1953.8156 - val_loss: 9305447.0000 - val_mae: 2473.6982\n",
            "Epoch 273/350\n",
            "3/3 - 0s - loss: 6297632.5000 - mae: 1946.6084 - val_loss: 9282126.0000 - val_mae: 2486.3811\n",
            "Epoch 274/350\n",
            "3/3 - 0s - loss: 6569548.5000 - mae: 1954.5742 - val_loss: 9167569.0000 - val_mae: 2480.3076\n",
            "Epoch 275/350\n",
            "3/3 - 0s - loss: 6502897.5000 - mae: 1944.8364 - val_loss: 9143218.0000 - val_mae: 2464.1262\n",
            "Epoch 276/350\n",
            "3/3 - 0s - loss: 6432013.5000 - mae: 1946.0013 - val_loss: 9038073.0000 - val_mae: 2452.4954\n",
            "Epoch 277/350\n",
            "3/3 - 0s - loss: 6896747.5000 - mae: 1979.3214 - val_loss: 8985151.0000 - val_mae: 2435.8118\n",
            "Epoch 278/350\n",
            "3/3 - 0s - loss: 6829570.0000 - mae: 2001.3822 - val_loss: 9153324.0000 - val_mae: 2494.4500\n",
            "Epoch 279/350\n",
            "3/3 - 0s - loss: 6594429.5000 - mae: 1948.1827 - val_loss: 9035767.0000 - val_mae: 2441.0291\n",
            "Epoch 280/350\n",
            "3/3 - 0s - loss: 6703201.5000 - mae: 1985.9559 - val_loss: 9219823.0000 - val_mae: 2472.3376\n",
            "Epoch 281/350\n",
            "3/3 - 0s - loss: 6430550.0000 - mae: 1964.0864 - val_loss: 9181947.0000 - val_mae: 2473.1494\n",
            "Epoch 282/350\n",
            "3/3 - 0s - loss: 6689720.0000 - mae: 1954.7843 - val_loss: 9313443.0000 - val_mae: 2485.3389\n",
            "Epoch 283/350\n",
            "3/3 - 0s - loss: 6373500.5000 - mae: 1934.2061 - val_loss: 9535185.0000 - val_mae: 2517.8806\n",
            "Epoch 284/350\n",
            "3/3 - 0s - loss: 6579661.5000 - mae: 1981.0951 - val_loss: 9504408.0000 - val_mae: 2511.6318\n",
            "Epoch 285/350\n",
            "3/3 - 0s - loss: 6410782.5000 - mae: 1948.4302 - val_loss: 9251054.0000 - val_mae: 2493.6265\n",
            "Epoch 286/350\n",
            "3/3 - 0s - loss: 6598642.5000 - mae: 1960.0219 - val_loss: 8926117.0000 - val_mae: 2418.9749\n",
            "Epoch 287/350\n",
            "3/3 - 0s - loss: 6673603.5000 - mae: 1956.8282 - val_loss: 9393263.0000 - val_mae: 2458.9011\n",
            "Epoch 288/350\n",
            "3/3 - 0s - loss: 6514747.5000 - mae: 1955.0571 - val_loss: 8969183.0000 - val_mae: 2423.3674\n",
            "Epoch 289/350\n",
            "3/3 - 0s - loss: 6508490.0000 - mae: 1931.1906 - val_loss: 9201279.0000 - val_mae: 2467.9636\n",
            "Epoch 290/350\n",
            "3/3 - 0s - loss: 6600209.5000 - mae: 1952.1960 - val_loss: 9683103.0000 - val_mae: 2509.1252\n",
            "Epoch 291/350\n",
            "3/3 - 0s - loss: 6770989.5000 - mae: 1968.1315 - val_loss: 9758953.0000 - val_mae: 2523.3035\n",
            "Epoch 292/350\n",
            "3/3 - 0s - loss: 6692525.5000 - mae: 1980.1562 - val_loss: 9410952.0000 - val_mae: 2518.7371\n",
            "Epoch 293/350\n",
            "3/3 - 0s - loss: 6438454.0000 - mae: 1947.5549 - val_loss: 9242512.0000 - val_mae: 2481.1895\n",
            "Epoch 294/350\n",
            "3/3 - 0s - loss: 6389940.5000 - mae: 1940.6934 - val_loss: 9263793.0000 - val_mae: 2482.1670\n",
            "Epoch 295/350\n",
            "3/3 - 0s - loss: 6483014.5000 - mae: 1950.8046 - val_loss: 9178007.0000 - val_mae: 2457.6624\n",
            "Epoch 296/350\n",
            "3/3 - 0s - loss: 6467242.0000 - mae: 1931.4955 - val_loss: 9215857.0000 - val_mae: 2447.4326\n",
            "Epoch 297/350\n",
            "3/3 - 0s - loss: 6338093.5000 - mae: 1943.5007 - val_loss: 9243617.0000 - val_mae: 2467.8108\n",
            "Epoch 298/350\n",
            "3/3 - 0s - loss: 6422714.5000 - mae: 1941.0785 - val_loss: 9012817.0000 - val_mae: 2440.1201\n",
            "Epoch 299/350\n",
            "3/3 - 0s - loss: 6492010.5000 - mae: 1952.6504 - val_loss: 9150515.0000 - val_mae: 2462.8687\n",
            "Epoch 300/350\n",
            "3/3 - 0s - loss: 6333994.0000 - mae: 1929.4231 - val_loss: 9244905.0000 - val_mae: 2468.7131\n",
            "Epoch 301/350\n",
            "3/3 - 0s - loss: 6387108.0000 - mae: 1933.2583 - val_loss: 9198456.0000 - val_mae: 2455.3811\n",
            "Epoch 302/350\n",
            "3/3 - 0s - loss: 6190076.5000 - mae: 1927.1775 - val_loss: 9292470.0000 - val_mae: 2465.5027\n",
            "Epoch 303/350\n",
            "3/3 - 0s - loss: 6375042.5000 - mae: 1968.1494 - val_loss: 9255763.0000 - val_mae: 2460.7175\n",
            "Epoch 304/350\n",
            "3/3 - 0s - loss: 6598001.5000 - mae: 1939.6161 - val_loss: 9043924.0000 - val_mae: 2437.0967\n",
            "Epoch 305/350\n",
            "3/3 - 0s - loss: 6914480.0000 - mae: 1981.3378 - val_loss: 9611860.0000 - val_mae: 2490.4023\n",
            "Epoch 306/350\n",
            "3/3 - 0s - loss: 6491577.5000 - mae: 1944.2030 - val_loss: 9280905.0000 - val_mae: 2465.0828\n",
            "Epoch 307/350\n",
            "3/3 - 0s - loss: 6459128.0000 - mae: 1919.6868 - val_loss: 9168205.0000 - val_mae: 2457.6133\n",
            "Epoch 308/350\n",
            "3/3 - 0s - loss: 6509334.5000 - mae: 1937.2369 - val_loss: 9249264.0000 - val_mae: 2470.0039\n",
            "Epoch 309/350\n",
            "3/3 - 0s - loss: 6467048.5000 - mae: 1928.7192 - val_loss: 8930607.0000 - val_mae: 2435.8030\n",
            "Epoch 310/350\n",
            "3/3 - 0s - loss: 6262848.0000 - mae: 1930.7386 - val_loss: 9195259.0000 - val_mae: 2450.4133\n",
            "Epoch 311/350\n",
            "3/3 - 0s - loss: 6675690.5000 - mae: 1954.2457 - val_loss: 9072403.0000 - val_mae: 2433.3684\n",
            "Epoch 312/350\n",
            "3/3 - 0s - loss: 6673156.5000 - mae: 1997.2919 - val_loss: 9687638.0000 - val_mae: 2483.1404\n",
            "Epoch 313/350\n",
            "3/3 - 0s - loss: 6264080.0000 - mae: 1943.1237 - val_loss: 9106127.0000 - val_mae: 2477.7844\n",
            "Epoch 314/350\n",
            "3/3 - 0s - loss: 6790119.5000 - mae: 1991.6448 - val_loss: 8889537.0000 - val_mae: 2452.3713\n",
            "Epoch 315/350\n",
            "3/3 - 0s - loss: 7056739.5000 - mae: 1987.0098 - val_loss: 9958471.0000 - val_mae: 2509.0193\n",
            "Epoch 316/350\n",
            "3/3 - 0s - loss: 6467829.5000 - mae: 1945.1599 - val_loss: 9329700.0000 - val_mae: 2498.4041\n",
            "Epoch 317/350\n",
            "3/3 - 0s - loss: 6597709.5000 - mae: 1927.4729 - val_loss: 9551799.0000 - val_mae: 2518.3213\n",
            "Epoch 318/350\n",
            "3/3 - 0s - loss: 6403378.5000 - mae: 1906.3162 - val_loss: 9414192.0000 - val_mae: 2487.2239\n",
            "Epoch 319/350\n",
            "3/3 - 0s - loss: 6367706.0000 - mae: 1923.6228 - val_loss: 9464687.0000 - val_mae: 2490.1924\n",
            "Epoch 320/350\n",
            "3/3 - 0s - loss: 6305880.5000 - mae: 1923.4344 - val_loss: 9064443.0000 - val_mae: 2450.5242\n",
            "Epoch 321/350\n",
            "3/3 - 0s - loss: 6378052.0000 - mae: 1920.2732 - val_loss: 9024615.0000 - val_mae: 2436.6509\n",
            "Epoch 322/350\n",
            "3/3 - 0s - loss: 6302583.5000 - mae: 1919.3003 - val_loss: 9256583.0000 - val_mae: 2459.7991\n",
            "Epoch 323/350\n",
            "3/3 - 0s - loss: 6214280.0000 - mae: 1908.5172 - val_loss: 9633031.0000 - val_mae: 2496.5229\n",
            "Epoch 324/350\n",
            "3/3 - 0s - loss: 6488189.5000 - mae: 1920.5016 - val_loss: 9566881.0000 - val_mae: 2487.2498\n",
            "Epoch 325/350\n",
            "3/3 - 0s - loss: 6218061.5000 - mae: 1909.6260 - val_loss: 9242201.0000 - val_mae: 2487.9319\n",
            "Epoch 326/350\n",
            "3/3 - 0s - loss: 6410876.5000 - mae: 1913.1498 - val_loss: 8957859.0000 - val_mae: 2425.1868\n",
            "Epoch 327/350\n",
            "3/3 - 0s - loss: 6506710.0000 - mae: 1963.7129 - val_loss: 8839208.0000 - val_mae: 2413.8586\n",
            "Epoch 328/350\n",
            "3/3 - 0s - loss: 6233692.0000 - mae: 1909.1769 - val_loss: 8941777.0000 - val_mae: 2428.5254\n",
            "Epoch 329/350\n",
            "3/3 - 0s - loss: 6225503.5000 - mae: 1910.9388 - val_loss: 9303629.0000 - val_mae: 2484.8572\n",
            "Epoch 330/350\n",
            "3/3 - 0s - loss: 6091970.0000 - mae: 1896.0266 - val_loss: 9608363.0000 - val_mae: 2490.1233\n",
            "Epoch 331/350\n",
            "3/3 - 0s - loss: 6461378.5000 - mae: 1922.0907 - val_loss: 9769513.0000 - val_mae: 2500.8811\n",
            "Epoch 332/350\n",
            "3/3 - 0s - loss: 6278468.0000 - mae: 1895.3945 - val_loss: 9253007.0000 - val_mae: 2498.7307\n",
            "Epoch 333/350\n",
            "3/3 - 0s - loss: 6369564.0000 - mae: 1901.0735 - val_loss: 9090116.0000 - val_mae: 2425.0725\n",
            "Epoch 334/350\n",
            "3/3 - 0s - loss: 6202834.0000 - mae: 1883.8451 - val_loss: 9415149.0000 - val_mae: 2457.2915\n",
            "Epoch 335/350\n",
            "3/3 - 0s - loss: 6308158.5000 - mae: 1909.4696 - val_loss: 9070375.0000 - val_mae: 2419.9875\n",
            "Epoch 336/350\n",
            "3/3 - 0s - loss: 6282823.5000 - mae: 1894.1267 - val_loss: 9058809.0000 - val_mae: 2426.5588\n",
            "Epoch 337/350\n",
            "3/3 - 0s - loss: 6067726.0000 - mae: 1891.8257 - val_loss: 9200272.0000 - val_mae: 2436.9236\n",
            "Epoch 338/350\n",
            "3/3 - 0s - loss: 6162136.0000 - mae: 1892.8546 - val_loss: 9186709.0000 - val_mae: 2438.7847\n",
            "Epoch 339/350\n",
            "3/3 - 0s - loss: 6069968.0000 - mae: 1890.9629 - val_loss: 8971857.0000 - val_mae: 2418.6360\n",
            "Epoch 340/350\n",
            "3/3 - 0s - loss: 6266329.5000 - mae: 1891.6896 - val_loss: 9066785.0000 - val_mae: 2433.3477\n",
            "Epoch 341/350\n",
            "3/3 - 0s - loss: 6168908.0000 - mae: 1898.3466 - val_loss: 9371381.0000 - val_mae: 2473.7620\n",
            "Epoch 342/350\n",
            "3/3 - 0s - loss: 6193906.5000 - mae: 1902.0864 - val_loss: 9303420.0000 - val_mae: 2466.3284\n",
            "Epoch 343/350\n",
            "3/3 - 0s - loss: 6167518.5000 - mae: 1881.7888 - val_loss: 9207920.0000 - val_mae: 2468.8215\n",
            "Epoch 344/350\n",
            "3/3 - 0s - loss: 6039712.5000 - mae: 1876.3759 - val_loss: 9205577.0000 - val_mae: 2458.4253\n",
            "Epoch 345/350\n",
            "3/3 - 0s - loss: 5944019.5000 - mae: 1888.2968 - val_loss: 9151168.0000 - val_mae: 2451.0837\n",
            "Epoch 346/350\n",
            "3/3 - 0s - loss: 6009946.5000 - mae: 1885.9258 - val_loss: 9090885.0000 - val_mae: 2433.6707\n",
            "Epoch 347/350\n",
            "3/3 - 0s - loss: 6125420.5000 - mae: 1901.4971 - val_loss: 9147532.0000 - val_mae: 2449.5310\n",
            "Epoch 348/350\n",
            "3/3 - 0s - loss: 6085070.5000 - mae: 1876.8129 - val_loss: 9177819.0000 - val_mae: 2450.2080\n",
            "Epoch 349/350\n",
            "3/3 - 0s - loss: 6174301.5000 - mae: 1879.7294 - val_loss: 9426003.0000 - val_mae: 2488.8779\n",
            "Epoch 350/350\n",
            "3/3 - 0s - loss: 6293365.5000 - mae: 1875.7263 - val_loss: 9452536.0000 - val_mae: 2494.4465\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcc73cdb4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk8wQuxQ6DpD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3747860c-3203-443f-f80e-36171a24110a"
      },
      "source": [
        "# make a prediction\n",
        "row = asarray([18024.0, 16722.0, 14385.0, 21342.0, 17180.0]).reshape((1, n_steps, 1))\n",
        "yhat = model.predict(row)\n",
        "print('Predicted: %.3f' % (yhat))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: 16277.778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUro20P76BOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eec96bdc-22d9-4c3a-e7b7-217361b66d86"
      },
      "source": [
        "# evaluate the model\n",
        "mse, mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('MSE: %.3f, RMSE: %.3f, MAE: %.3f' % (mse, sqrt(mse), mae))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 9452536.000, RMSE: 3074.498, MAE: 2494.447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKR06fgxGQKM",
        "colab_type": "text"
      },
      "source": [
        "### How to Use Advanced Model Features\n",
        "\n",
        "**Visualizing Deep Learning Models - Text Descriptions and Plots**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gXGp9UHH57O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "6b19b804-c955-41d5-9679-1aa8a5d9de68"
      },
      "source": [
        "# Text Description\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(8,)))\n",
        "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# summarize the model\n",
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_18 (Dense)             (None, 10)                90        \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 8)                 88        \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 187\n",
            "Trainable params: 187\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqGHPUEAITCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "d5aaad3e-d594-4afc-a2a2-dbec91c16b4f"
      },
      "source": [
        "#Architecture Plot\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(8,)))\n",
        "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# summarize the model\n",
        "plot_model(model, 'model.png', show_shapes=True)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY6IQ-R2Ihl-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "be2b80cd-5b45-40ca-f2ac-e5938575af61"
      },
      "source": [
        "# Plotting the Learning Curve\n",
        "# Requires fit function that references a validation dataset\n",
        "# which can be done manually or with validation_split argument\n",
        "# Fit function will return 'history' object that enables plot\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# create the dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
        "# determine the number of input features\n",
        "n_features = X.shape[1]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile the model\n",
        "sgd = SGD(learning_rate=0.001, momentum=0.8)\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy')\n",
        "\n",
        "# fit the model\n",
        "history = model.fit(X, y, epochs=100, batch_size=32, verbose=0, validation_split=0.3)\n",
        "\n",
        "# plot learning curves\n",
        "pyplot.title('Learning Curves')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Cross Entropy')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='val')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wn2tH8hJWxj",
        "colab_type": "text"
      },
      "source": [
        "How to Save and load your Model\n",
        "\n",
        "Employs save() and load_model() functions. Uses H5 format, which requires that h5py library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDrh2oyvJtJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of saving a fit model\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# create the dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=4, n_classes=2, random_state=1)\n",
        "\n",
        "# determine the number of input features\n",
        "n_features = X.shape[1]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile the model\n",
        "sgd = SGD(learning_rate=0.001, momentum=0.8)\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy')\n",
        "\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=100, batch_size=32, verbose=0, validation_split=0.3)\n",
        "\n",
        "# save model to file\n",
        "model.save('model.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lputGgDKDa8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b50b49d5-6fcd-4f3c-8c8b-8be49125f5b2"
      },
      "source": [
        "# Loading saved model\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# create the dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=4, n_classes=2, random_state=1)\n",
        "\n",
        "# load the model from file\n",
        "model = load_model('model.h5')\n",
        "\n",
        "# make a prediction\n",
        "row = [1.91518414, 1.14995454, -1.52847073, 0.79430654]\n",
        "yhat = model.predict([row])\n",
        "print('Predicted: %.3f' % yhat[0])\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted: 0.887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmyVUtUMEFgx",
        "colab_type": "text"
      },
      "source": [
        "### How to Get Better Model Performance\n",
        "\n",
        "**How to Reduce Overfitting with Dropout**\n",
        "\n",
        "Dropout is a regularization method that reduces overfitting of the training dataset and makes the model more robust. It's achieved during training, where some number of layer outputs are randomly ignored or 'dropped out.' This has the effect of making the training process noisy, forcing nodes within a layer to probabilistically take on more or less responsibility for inputs.\n",
        "\n",
        "It can be used with MLP, CNN and RNN models.  The dropout is specified when you define your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMkoKPy-G2Nn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ee10043-0a73-4b06-dd70-d8d11e028911"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# create the dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
        "\n",
        "# determine the number of input features\n",
        "n_features = X.shape[1]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "# here is the dropout\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=100, batch_size=32, verbose=0)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcc7155f748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll0260eOHe3F",
        "colab_type": "text"
      },
      "source": [
        "**How to Accelerate Training with Batch Normalization**\n",
        "\n",
        "Scale and distribution of inputs can impact how easily or quickly a layer is trained. This is why it's a good idea to scale input data prior to modeling with NNM.\n",
        "\n",
        "Batch normalization is the technique for training very deep neural networks that standardizes inputs for each minin-batch. This stablizes the learning process and reduces the number of epochs that are needed.\n",
        "\n",
        "You can normalize by adding a batch normalization layer prior to the layer you wish to have standardized inputs.  BN can run with MLP, CNN and RNN models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIRE-2JpIj_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0472eee-c809-4478-db91-63e5eedf4d3e"
      },
      "source": [
        "# example of batch normalization\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# create the dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
        "\n",
        "# determine the number of input features\n",
        "n_features = X.shape[1]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "# here's the batching\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=100, batch_size=32, verbose=0)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcc7155f7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO5Lm28BI_Xv",
        "colab_type": "text"
      },
      "source": [
        "Halting Training at the Right Time with Early Stopping\n",
        "\n",
        "This involves monitoring the loss on the training dataset and validation dataset. As soon as the loss for the validation set starts showing signs of 'overfitting' the process can be stopped.\n",
        "\n",
        "Requires a validation dataset. You can then defining EarlyStopping and instruct it on which performance measures to monitor and the number of epochs to observe the overfitting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVfEyLEkJn1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of using early stopping\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# create the dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
        "\n",
        "# determine the number of input features\n",
        "n_features = X.shape[1]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# configure early stopping\n",
        "es = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "# fit the model\n",
        "history = model.fit(X, y, epochs=200, batch_size=32, verbose=0, validation_split=0.3, callbacks=[es])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0eQvwDEKNLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}